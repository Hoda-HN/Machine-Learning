{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Tweets Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Hoda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hoda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hoda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1161040537207463936</td>\n",
       "      <td>'RT @SenJeffMerkley: The Endangered Species Ac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1176360756239118342</td>\n",
       "      <td>'RT @LindseyGrahamSC: Interesting concept -- i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1099036648573145088</td>\n",
       "      <td>'RT @RealJamesWoods: #BuildTheWall #DeportThem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1092915693203480577</td>\n",
       "      <td>'RT @PatriotJackiB: Why would the MEXICAN GOV’...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1149038450668187654</td>\n",
       "      <td>'RT @TheOnion: Sweden Announces Plan To Get 10...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1161040537207463936  'RT @SenJeffMerkley: The Endangered Species Ac...   \n",
       "1  1176360756239118342  'RT @LindseyGrahamSC: Interesting concept -- i...   \n",
       "2  1099036648573145088  'RT @RealJamesWoods: #BuildTheWall #DeportThem...   \n",
       "3  1092915693203480577  'RT @PatriotJackiB: Why would the MEXICAN GOV’...   \n",
       "4  1149038450668187654  'RT @TheOnion: Sweden Announces Plan To Get 10...   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      1  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweets_labeled.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1161040537207463936</td>\n",
       "      <td>['endangered', 'species', 'act', 'saved', 'bal...</td>\n",
       "      <td>1</td>\n",
       "      <td>['endanger', 'specie', 'act', 'save', 'bald', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1176360756239118342</td>\n",
       "      <td>['interesting', 'concept', 'impeach', 'first',...</td>\n",
       "      <td>1</td>\n",
       "      <td>['interest', 'concept', 'impeach', 'first', 'f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1099036648573145088</td>\n",
       "      <td>['buildthewall', 'deportthemall']</td>\n",
       "      <td>0</td>\n",
       "      <td>['buildthewall', 'deportthemall']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1092915693203480577</td>\n",
       "      <td>['would', 'mexican', 'gov', '’', 't', 'fund', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['would', 'mexican', 'gov', 'fund', 'cahoot']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1149038450668187654</td>\n",
       "      <td>['sweden', 'announces', 'plan', 'get', '100', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['sweden', 'announces', 'plan', 'get', 'energy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1161040537207463936  ['endangered', 'species', 'act', 'saved', 'bal...   \n",
       "1  1176360756239118342  ['interesting', 'concept', 'impeach', 'first',...   \n",
       "2  1099036648573145088                  ['buildthewall', 'deportthemall']   \n",
       "3  1092915693203480577  ['would', 'mexican', 'gov', '’', 't', 'fund', ...   \n",
       "4  1149038450668187654  ['sweden', 'announces', 'plan', 'get', '100', ...   \n",
       "\n",
       "   label                                         text_final  \n",
       "0      1  ['endanger', 'specie', 'act', 'save', 'bald', ...  \n",
       "1      1  ['interest', 'concept', 'impeach', 'first', 'f...  \n",
       "2      0                  ['buildthewall', 'deportthemall']  \n",
       "3      0      ['would', 'mexican', 'gov', 'fund', 'cahoot']  \n",
       "4      0  ['sweden', 'announces', 'plan', 'get', 'energy...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweets_lemma.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(df['text_final'],df['label'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=500)\n",
    "Tfidf_vect.fit(df['text_final'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'act': 8, 'sign': 418, 'law': 260, 'republican': 387, 'president': 359, 'nothing': 318, 'interest': 234, 'impeach': 229, 'first': 176, 'find': 174, 'fact': 166, 'sound': 424, 'like': 271, 'mainstream': 282, 'medium': 293, 'write': 496, 'story': 431, 'buildthewall': 69, 'deportthemall': 129, 'would': 495, 'mexican': 296, 'announces': 24, 'plan': 344, 'get': 189, 'wall': 473, 'warren': 476, 'congress': 101, 'fail': 167, 'impeachment': 230, 'trump': 457, 'current': 110, 'former': 179, 'staff': 425, 'state': 426, 'department': 127, 'say': 398, 'ukraine': 464, 'bombshell': 57, 'much': 305, 'top': 453, 'diplomat': 131, 'real': 377, 'time': 450, 'urge': 466, 'woman': 491, 'abortion': 3, 'aag': 0, 'country': 106, 'must': 309, 'abc': 1, 'away': 38, 'show': 416, 'oscar': 331, 'back': 40, 'israel': 239, 'breitbart': 65, 'via': 469, 'bring': 67, 'visa': 470, 'overstayers': 332, 'across': 7, 'wide': 486, 'open': 330, 'border': 59, 'drug': 140, 'cartel': 78, 'million': 299, 'elect': 145, 'rep': 384, 'general': 188, 'raise': 374, 'study': 432, 'cnn': 96, 'search': 403, 'engine': 149, 'google': 197, 'result': 390, 'overwhelmingly': 333, 'favor': 171, 'duckduckgo': 141, 'good': 196, 'king': 253, 'adviser': 14, 'golden': 195, 'globe': 192, 'antigun': 26, 'hollywood': 219, 'surrounded': 437, 'security': 405, 'arm': 28, 'guard': 204, 'jussie': 247, 'attorney': 33, 'whistleblower': 484, 'tell': 444, 'news': 316, 'mcconnell': 290, 'agree': 15, 'hold': 218, 'trial': 454, 'gop': 198, 'senate': 407, 'charge': 85, 'democrat': 121, 'leave': 263, 'kill': 252, 'never': 314, 'win': 488, 'another': 25, 'election': 146, 'burger': 70, 'new': 315, 'child': 88, 'one': 329, 'talk': 441, 'promise': 364, 'protest': 367, 'attack': 32, 'right': 392, 'look': 277, 'truly': 456, 'really': 378, 'freedom': 182, 'young': 499, 'man': 284, 'able': 2, 'hand': 208, 'without': 490, 'crime': 109, 'try': 458, 'hamaswing': 207, 'party': 335, 'defend': 120, 'rabid': 373, 'bigot': 52, 'omar': 328, 'mass': 288, 'sick': 417, 'bill': 53, 'make': 283, 'face': 164, 'democratic': 122, 'sure': 436, 'grandparent': 201, 'allow': 19, 'enter': 151, 'measure': 292, 'flee': 177, 'poverty': 356, 'become': 44, 'bricklayer': 66, 'excellent': 157, 'piece': 342, 'cia': 90, 'prepares': 358, 'blame': 56, 'consultant': 102, 'excuse': 158, 'screw': 402, 'pooch': 351, 'steele': 428, 'dossier': 136, 'break': 64, 'nyt': 320, 'second': 404, 'intel': 232, 'official': 323, 'whether': 483, 'file': 173, 'vote': 472, 'mitch': 301, 'need': 313, 'since': 419, 'already': 20, 'accuse': 5, 'want': 474, 'leader': 261, 'kamala': 249, 'harris': 211, 'take': 440, 'gun': 205, 'dealer': 116, 'license': 268, 'executive': 160, 'action': 9, 'house': 220, 'pass': 336, 'send': 409, 'push': 370, 'facebook': 165, 'ban': 41, 'project': 363, 'veritas': 468, 'exec': 159, 'decries': 118, 'prevent': 362, 'happen': 209, 'report': 385, 'believe': 47, 'smollett': 420, 'pay': 338, 'two': 463, 'men': 295, 'know': 254, 'direct': 132, 'bradley': 62, 'cooper': 103, 'htt': 221, 'case': 79, 'foreign': 178, 'government': 199, 'stop': 430, 'use': 467, 'bryce': 68, 'harper': 210, 'ask': 31, 'phillies': 341, 'willing': 487, 'move': 303, 'city': 91, 'administration': 12, 'deny': 126, 'behind': 45, 'jared': 241, 'kushner': 256, 'promotion': 365, 'work': 492, 'baby': 39, 'california': 74, 'illegal': 225, 'alien': 16, 'school': 400, 'worker': 493, 'porn': 352, 'possession': 353, 'lastditch': 258, 'climate': 94, 'change': 84, 'provide': 368, 'location': 276, 'weapon': 478, 'whereabouts': 482, 'oil': 325, 'police': 346, 'officer': 322, 'job': 243, 'white': 485, 'krassensteins': 255, 'disappear': 133, 'twitter': 462, 'deactivation': 114, 'arrest': 29, 'evidence': 156, 'mean': 291, 'least': 262, 'tom': 452, 'brady': 63, 'accept': 4, 'super': 434, 'bowl': 60, 'trophy': 455, 'id': 224, 'ole': 327, 'fascist': 170, 'amp': 23, 'drop': 139, 'think': 449, 'public': 369, 'el': 144, 'donald': 135, 'jr': 245, 'covington': 108, 'catholic': 81, 'hoax': 217, 'target': 442, 'fake': 168, 'dedicate': 119, 'russell': 395, 'westbrook': 481, 'stay': 427, 'late': 259, 'practice': 357, 'miss': 300, 'extra': 163, 'shot': 415, 'acosta': 6, 'admit': 13, 'reporter': 386, 'serious': 410, 'author': 34, 'either': 143, 'patriot': 337, 'play': 345, 'game': 187, 'life': 270, 'billion': 54, 'people': 340, 'doesnt': 134, 'end': 148, 'call': 75, 'enough': 150, 'american': 22, 'socalled': 421, 'green': 202, 'deal': 115, 'old': 326, 'marxism': 287, 'dems': 125, 'support': 435, 'love': 280, 'hell': 214, 'every': 155, 'maga': 281, 'political': 348, 'may': 289, 'year': 497, 'claim': 92, 'lie': 269, 'multiple': 306, 'tv': 460, 'la': 257, 'bar': 42, 'switch': 438, 'dad': 111, 'rerun': 389, 'complaint': 100, 'half': 206, 'queen': 372, 'elizabeth': 147, 'request': 388, 'migrant': 297, 'family': 169, 'immigration': 228, 'policy': 347, 'tweet': 461, 'exist': 161, 'immigrant': 227, 'likely': 272, 'come': 98, 'forward': 180, 'mark': 286, 'poll': 349, 'still': 429, 'america': 21, 'china': 89, 'help': 215, 'give': 191, 'investigation': 236, 'big': 51, 'potentially': 355, 'jessye': 242, 'norman': 317, 'regal': 381, 'soprano': 423, 'die': 130, 'grammy': 200, 'award': 37, 'winner': 489, 'shimmer': 414, 'voice': 471, 'br': 61, 'list': 273, 'draft': 137, 'turn': 459, 'cnnpolitics': 97, 'barr': 43, 'investigate': 235, 'york': 498, 'legal': 264, 'billionaire': 55, 'deport': 128, 'cent': 83, 'allege': 18, 'isi': 238, 'lottery': 279, 'live': 275, 'day': 113, 'justice': 248, 'well': 480, 'texas': 446, 'decade': 117, 'tax': 443, 'kid': 251, 'keep': 250, 'bidens': 50, 'campaign': 76, 'coming': 99, 'thanks': 447, 'clintonlinked': 95, 'nunes': 319, 'schiff': 399, 'let': 265, 'chicago': 87, 'court': 107, 'even': 154, 'book': 58, 'mr': 304, 'obama': 321, 'iran': 237, 'could': 105, 'intelligence': 233, 'dangerous': 112, 'literally': 274, 'buy': 73, 'democratvoterfraud': 123, 'war': 475, 'im': 226, 'go': 193, 'refuse': 380, 'lose': 278, 'human': 222, 'way': 477, 'jar': 240, 'goff': 194, 'piss': 343, 'friend': 185, 'sue': 433, 'meet': 294, 'nation': 310, 'senator': 408, 'letter': 266, 'prosecutor': 366, 'high': 216, 'put': 371, 'check': 86, 'pompeo': 350, 'thing': 448, 'russia': 396, 'fromsoftware': 186, 'partnership': 334, 'eric': 153, 'carle': 77, 'set': 413, 'world': 494, 'hungry': 223, 'caterpillar': 80, 'freedomwielding': 184, 'schooler': 401, 'classmate': 93, 'freedoming': 183, 'eight': 142, 'epstein': 152, 'rape': 375, 'allegation': 17, 'money': 302, 'ukrainian': 465, 'today': 451, 'remove': 383, 'record': 379, 'joe': 244, 'federal': 172, 'hate': 212, 'nearly': 312, 'national': 311, 'release': 382, 'include': 231, 'article': 30, 'censorship': 82, 'pretend': 361, 'see': 406, 'many': 285, 'often': 324, 'service': 412, 'muslim': 308, 'son': 422, 'serve': 411, 'post': 354, 'syria': 439, 'bush': 72, 'expect': 162, 'level': 267, 'revoke': 391, 'authority': 35, 'admin': 11, 'giant': 190, 'demonic': 124, 'burst': 71, 'ground': 203, 'drag': 138, 'belichick': 46, 'testify': 445, 'hear': 213, 'run': 394, 'fire': 175, 'presidential': 360, 'cost': 104, 'judge': 246, 'rule': 393, 'penny': 339, 'biden': 49, 'bernie': 48, 'sander': 397, 'activist': 10, 'wear': 479, 'auto': 36, 'murderer': 307, 'mileage': 298, 'fox': 181, 'rapist': 376, 'aoc': 27}\n"
     ]
    }
   ],
   "source": [
    "print(Tfidf_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 472)\t0.4580268988013137\n",
      "  (0, 274)\t0.5067257003524875\n",
      "  (0, 123)\t0.5222693093853752\n",
      "  (0, 73)\t0.5105636033354273\n",
      "  (1, 473)\t0.6541707471184155\n",
      "  (1, 313)\t0.7563469003139593\n",
      "  (2, 497)\t0.34295532022958264\n",
      "  (2, 363)\t0.35613401762073094\n",
      "  (2, 355)\t0.4112280117987512\n",
      "  (2, 299)\t0.3822505982487896\n",
      "  (2, 225)\t0.28490145205381584\n",
      "  (2, 206)\t0.3928781958151451\n",
      "  (2, 151)\t0.3379720181127024\n",
      "  (2, 16)\t0.3009634747166519\n",
      "  (3, 379)\t0.5009909167541877\n",
      "  (3, 321)\t0.4897958006178765\n",
      "  (3, 311)\t0.4779084159376224\n",
      "  (3, 293)\t0.3911884937971185\n",
      "  (3, 22)\t0.3573279772472712\n",
      "  (4, 492)\t0.421781881489518\n",
      "  (4, 398)\t0.3220179243045334\n",
      "  (4, 310)\t0.4999052725752578\n",
      "  (4, 294)\t0.504686044363132\n",
      "  (4, 215)\t0.4623756221410403\n",
      "  (5, 491)\t0.42186595468234817\n",
      "  :\t:\n",
      "  (157779, 467)\t0.3602822138727755\n",
      "  (157779, 369)\t0.42717371941493404\n",
      "  (157779, 172)\t0.8292884539218804\n",
      "  (157780, 464)\t0.27564570860205895\n",
      "  (157780, 383)\t0.40701630292991603\n",
      "  (157780, 366)\t0.40262127569758094\n",
      "  (157780, 313)\t0.34846676174848545\n",
      "  (157780, 266)\t0.39829029952494444\n",
      "  (157780, 92)\t0.38325467348320374\n",
      "  (157780, 30)\t0.4114667536366958\n",
      "  (157781, 484)\t0.40155614106909354\n",
      "  (157781, 450)\t0.3488522269941287\n",
      "  (157781, 404)\t0.4915261367452475\n",
      "  (157781, 398)\t0.3302751607909204\n",
      "  (157781, 385)\t0.4294356323503979\n",
      "  (157781, 254)\t0.42656793365133894\n",
      "  (157782, 457)\t0.18182116648729524\n",
      "  (157782, 340)\t0.3387411446413886\n",
      "  (157782, 264)\t0.37817583730979887\n",
      "  (157782, 228)\t0.3488555925298176\n",
      "  (157782, 126)\t0.3571606059538458\n",
      "  (157782, 106)\t0.37978517501752274\n",
      "  (157782, 25)\t0.3291000159160991\n",
      "  (157782, 12)\t0.314855078303012\n",
      "  (157782, 9)\t0.32899436706783053\n"
     ]
    }
   ],
   "source": [
    "print(Train_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  88.41944929165064\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
